{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anusha\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_first\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization, regularizers\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical\n",
    "K.set_image_dim_ordering('th')\n",
    "print(K.image_data_format())\n",
    "\n",
    "## required for efficient GPU use\n",
    "import tensorflow as tf\n",
    "from keras.backend import tensorflow_backend\n",
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "session = tf.Session(config=config)\n",
    "tensorflow_backend.set_session(session)\n",
    "## required for efficient GPU use\n",
    "\n",
    "import os\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np # linear algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='D:/AI/Jinoh Kim/one_class_svm/intrusion/Final_data/cnn_deep_mon.h5'\n",
    "\n",
    "# prepare callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_acc', \n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        verbose=1),\n",
    "    ModelCheckpoint(model_path,\n",
    "        monitor='val_acc', \n",
    "        save_best_only=True, \n",
    "        mode='max',\n",
    "        verbose=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (52991, 78)\n",
      "y_train shape: (52991, 2)\n",
      "x_test shape: (69270, 78)\n",
      "y_test shape: (69270, 2)\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "\n",
    "class dataset:\n",
    "    monday = pd.read_pickle(\"D:/AI/Jinoh Kim/one_class_svm/intrusion/Final_data/preprocessed_monday_reduced_final.pkl\")\n",
    "    wednesday = pd.read_pickle(\"D:/AI/Jinoh Kim/one_class_svm/intrusion/Final_data/preprocessed_wednesday_final_data.pkl\")\n",
    "    \n",
    "    \n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['label_0','label_1']\n",
    "    \n",
    "    x_input = dataset.monday.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.monday.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.wednesday.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.wednesday.loc[:,output_columns_2labels]\n",
    "    \n",
    "    ss = pp.StandardScaler()\n",
    "    \n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.fit_transform(x_test_input)\n",
    "    \n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "        \n",
    "    print('x_train shape: {}'.format(x_train.shape))\n",
    "    print('y_train shape: {}'.format(y_train.shape))\n",
    "    print('x_test shape: {}'.format(x_test.shape))\n",
    "    print('y_test shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape after reshape: (52991, 78, 1)\n",
      "test shape after reshape: (69270, 78, 1)\n"
     ]
    }
   ],
   "source": [
    "#reshape data\n",
    "X_train = np.reshape(preprocess.x_train, (preprocess.x_train.shape[0], preprocess.x_train.shape[1], 1))\n",
    "X_test = np.reshape(preprocess.x_test, (preprocess.x_test.shape[0], preprocess.x_test.shape[1], 1))\n",
    "\n",
    "print('train shape after reshape: {}'.format(X_train.shape))\n",
    "print('test shape after reshape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of parameters\n",
    "batch_size = 1000\n",
    "num_classes = 2\n",
    "epochs = 10\n",
    "filter_size=3\n",
    "#noise = 1\n",
    "droprate=0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anusha\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, kernel_size=3, activation=\"relu\", padding=\"same\")`\n",
      "  if sys.path[0] == '':\n",
      "c:\\users\\anusha\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(256, kernel_size=3, activation=\"relu\", padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 78, 64)            256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 78, 64)            256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 78, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 78, 128)           24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 78, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 77, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 77, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 77, 256)           98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 77, 256)           1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 76, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 76, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 19456)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1245184   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2048      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 1,373,538\n",
      "Trainable params: 1,372,418\n",
      "Non-trainable params: 1,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Start Neural Network\n",
    "model = Sequential()\n",
    "\n",
    "#convolution 1st layer\n",
    "model.add(Conv1D(64, kernel_size=(filter_size), padding=\"same\",\n",
    "                 activation='relu',\n",
    "                 input_shape=(78, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(droprate))\n",
    "          \n",
    "#convolution 2nd layer\n",
    "model.add(Conv1D(128, kernel_size=(filter_size), activation='relu', border_mode=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(strides=1))\n",
    "model.add(Dropout(droprate))\n",
    "\n",
    "#convolution 3rd layer\n",
    "model.add(Conv1D(256, kernel_size=(filter_size), activation='relu', border_mode=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(strides=1))\n",
    "model.add(Dropout(droprate))\n",
    "\n",
    "#FCN 1st layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(droprate))\n",
    "\n",
    "#FCN 2nd layer\n",
    "model.add(Dense(32,use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(droprate))\n",
    "\n",
    "#FCN 3rd layer\n",
    "model.add(Dense(16,use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(droprate))\n",
    "\n",
    "#FCN final layer\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52991 samples, validate on 69270 samples\n",
      "Epoch 1/10\n",
      "52991/52991 [==============================] - 1371s 26ms/step - loss: 0.8921 - acc: 0.4532 - val_loss: 0.6157 - val_acc: 0.8997\n",
      "Epoch 2/10\n",
      "52991/52991 [==============================] - 1248s 24ms/step - loss: 0.5395 - acc: 0.8463 - val_loss: 0.4490 - val_acc: 0.9162\n",
      "Epoch 3/10\n",
      "52991/52991 [==============================] - 992s 19ms/step - loss: 0.3348 - acc: 0.9400 - val_loss: 0.3690 - val_acc: 0.9164\n",
      "Epoch 4/10\n",
      "52991/52991 [==============================] - 989s 19ms/step - loss: 0.2218 - acc: 0.9788 - val_loss: 0.3122 - val_acc: 0.9164\n",
      "Epoch 5/10\n",
      "52991/52991 [==============================] - 670s 13ms/step - loss: 0.1571 - acc: 0.9935 - val_loss: 0.2898 - val_acc: 0.9164\n",
      "Epoch 6/10\n",
      "52991/52991 [==============================] - 506s 10ms/step - loss: 0.1187 - acc: 0.9965 - val_loss: 0.2883 - val_acc: 0.9164\n",
      "Epoch 7/10\n",
      "52991/52991 [==============================] - 498s 9ms/step - loss: 0.0936 - acc: 0.9986 - val_loss: 0.2958 - val_acc: 0.9164\n",
      "Epoch 8/10\n",
      "52991/52991 [==============================] - 496s 9ms/step - loss: 0.0756 - acc: 0.9993 - val_loss: 0.3157 - val_acc: 0.9164\n",
      "Epoch 9/10\n",
      "52991/52991 [==============================] - 502s 9ms/step - loss: 0.0633 - acc: 0.9993 - val_loss: 0.3472 - val_acc: 0.9164\n",
      "Epoch 10/10\n",
      "52991/52991 [==============================] - 501s 9ms/step - loss: 0.0533 - acc: 0.9997 - val_loss: 0.3699 - val_acc: 0.9164\n",
      "Test loss: 0.36988863867737265\n",
      "Test accuracy: 0.9163851595207161\n"
     ]
    }
   ],
   "source": [
    "#Save Model=ON\n",
    "history = model.fit(X_train, preprocess.y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, preprocess.y_test),shuffle=True,callbacks=callbacks)\n",
    "\n",
    "score = model.evaluate(X_test, preprocess.y_test, verbose=0)\n",
    "\n",
    "#print loss and accuracy\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.93999684 0.06000319]\n",
      " [0.96740615 0.03259385]\n",
      " [0.97215074 0.02784929]\n",
      " ...\n",
      " [0.9710032  0.02899683]\n",
      " [0.97426087 0.02573917]\n",
      " [0.9692654  0.03073466]]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9164    1.0000    0.9564     63478\n",
      "          1     0.0000    0.0000    0.0000      5792\n",
      "\n",
      "avg / total     0.8398    0.9164    0.8764     69270\n",
      "\n",
      "[[63478     0]\n",
      " [ 5792     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anusha\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(y_pred)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "p=model.predict_proba(X_test)\n",
    "\n",
    "target_names = ['0', '1']\n",
    "print(classification_report(np.argmax(preprocess.y_test, axis=1), y_pred, target_names=target_names, digits=4))\n",
    "print(confusion_matrix(np.argmax(preprocess.y_test, axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
